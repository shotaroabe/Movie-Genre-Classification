# -*- coding: utf-8 -*-
"""Copy of ShotTesting_BigDataEnergy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C8v8pyERJO1lxU9-2igjAxwou_-9BVj8
"""

!unzip train_posters.zip
!unzip test_posters.zip

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from keras.utils import to_categorical
import os
import cv2
import matplotlib.pyplot as plt

# Read csv data
# Reorder the labels to match the order of the images

csv_data = pd.read_csv('train_data.csv').as_matrix()

csv_data = csv_data[csv_data[:,1].argsort()] # csv_data[:,1].argsort() returns indices that sort movies by imdb # 
genres = csv_data[:,-1]


test_data_csv = pd.read_csv('test_data.csv').as_matrix()

# One-hot encode genres column

train_labels = to_categorical(np.array(genres))
#print("Label for first training example: {}".format(genres[0]))
#print("One-hot encoded label for first training example: {}".format(train_labels[0]))

import random
import numpy as np

test_list = list(range(3094))
#print(test_list)
train_list = list(range(3094))
#print(train_list)

test_rand = random.sample(test_list, 343)
train_rand = list(set(train_list) - set(test_rand))

#print(test_rand)
#print(train_rand)

test_genre = csv_data[test_rand,-1]
train_genre = csv_data[train_rand,-1]

row_idx1 = np.array(test_rand)
col_idx1 = np.array([3,4,5])
test_array = csv_data[row_idx1[:, None], col_idx1]
#print(test_array)

row_idx2 = np.array(train_rand)
col_idx2 = np.array([3,4,5])
train_array = csv_data[row_idx2[:, None], col_idx2]
#print(train_array.shape)

row_idx3 = np.array(train_rand)
col_idx3 = np.array([4,5])
train_array_knn = csv_data[row_idx3[:, None], col_idx3]
#print(train_array_knn.shape)

row_idx4 = np.array(test_rand)
col_idx4 = np.array([4,5])
test_array_knn = csv_data[row_idx4[:, None], col_idx4]

train_data = 'train_posters'
test_data = 'test_posters'

def preprocess_training_data():
    train_images = []
    image_num = 0

    for ind,i in enumerate(csv_data[:,1]):

        path = os.path.join(train_data,str(i) + ".jpg")
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (64,64))

        train_images.append(np.array(img)/255)
    return train_images


def preprocess_test_data():
    test_images = []
    for ind,i in enumerate(test_data_csv[:,1]):

        path = os.path.join(test_data,str(i) + ".jpg")
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (64,64))
        test_images.append(np.array(img)/255)
            
    return test_images
    
preprocessed_train = preprocess_training_data()
preprocessed_test = preprocess_test_data()


x_train = np.array(preprocessed_train).reshape(-1,64,64,1)
y_train = train_labels

x_test = np.array(preprocessed_test).reshape(-1,64,64,1)
x_test.shape

# Display training example #1371 Death Note, a well-acclaimed Hollywood adaption of the Death Note anime (jk)
# Display movie poster and associated label and title

# Feel free to change the train_ind and see how the preprocessing affect the images
train_ind = 1371
plt.imshow(preprocessed_train[train_ind])
#print(csv_data[:,1][train_ind])
#print(y_train[train_ind])
print(csv_data[:,(3,4,5)])

# Displaying test example #200 
# Remember there is no genre label or title associated with this image
# We are trying to predict the labels! 

plt.imshow(preprocessed_test[200])
print("Test example #200")

import numpy as np

cross_testx = x_train[test_rand]
cross_trainx = np.delete(x_train, test_rand, 0)
cross_trainy =np.delete(y_train, test_rand, 0)

from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras import backend as K
from keras.optimizers import adam, SGD 
import numpy as np
import keras
from sklearn.preprocessing import OneHotEncoder
y_train = keras.utils.np_utils.to_categorical(cross_trainy)
y_test = keras.utils.np_utils.to_categorical(test_genre)






model = Sequential()

model.add(InputLayer(input_shape=[64,64,1]))



model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))



model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(4, activation='softmax'))
opt = SGD(lr=0.01)
model.compile(loss='categorical_crossentropy',
              optimizer="adam",
              metrics=['accuracy'])


train_datagen = ImageDataGenerator(
    #rescale=1. / 255,
    #shear_range=0.03,
    #zoom_range=0.2,
    #horizontal_flip=True
    zca_whitening = 1,
    rotation_range=15,
                               #width_shift_range=0.1,
                               #height_shift_range=0.1,
                               #shear_range=0.01,
                               #zoom_range=[0.9, 1.25],
                               #featurewise_center = 1,
                               #horizontal_flip=True,
                               #vertical_flip=False,
                               #fill_mode='reflect',
                               #data_format='channels_last',
                               #brightness_range=[0.5, 1.5]
    )

test_datagen = ImageDataGenerator()


train_generator = train_datagen.flow(x=cross_trainx,y=cross_trainy,
    #target_size = (64, 64),
    batch_size=32)
    #class_mode='classification')

validation_generator = test_datagen.flow(x=cross_testx,y=y_test,
    #target_size=(64, 64),
    batch_size=32)
    #class_mode='classification')


# fits the model on batches with real-time data augmentation:
                                         
model.fit_generator(train_generator, 
                   steps_per_epoch = 128, 
                   epochs = 45, 
                   validation_data = validation_generator, 
                   validation_steps =  len(y_test))

                                         
       #model.fit_generator(datagen.flow(x=cross_trainx,y=cross_trainy, batch_size=64),
# steps_per_epoch=len(cross_trainx) / 64, epochs=20

model.summary()
  
model.save("movie_classifier.h5py")

predict = model.predict(cross_testx, batch_size=32, verbose=0, steps=None)
#predict = model.predict(x_test, batch_size=32, verbose=0, steps=None)

'''
from keras import Sequential
from keras.layers import InputLayer, Conv2D, MaxPool2D, Flatten, Dense
import numpy as np

predict_new = np.zeros((343, 4))

for x in range(10):

  model = Sequential()

  model.add(InputLayer(input_shape=[64,64,1]))
  model.add(Conv2D(filters=32,kernel_size=(3,3),padding='same',activation='relu'))
  model.add(MaxPool2D(pool_size=(2,2),padding='same'))

  model.add(Flatten())
  model.add(Dense(128, activation='relu'))
  model.add(Dense(4, activation='softmax'))

  model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

#for cross val
  model.fit(x=cross_trainx, y=cross_trainy, epochs=6, batch_size=55)

#for submission
  #model.fit(x=x_train, y=y_train, epochs=6, batch_size=55)

  model.summary()
  
  model.save("movie_classifier.h5py")

  predict = model.predict(cross_testx, batch_size=32, verbose=0, steps=None)
  
  predict_new = predict_new + predict

predict_avg = predict_new/7.3
'''

from sklearn.svm import LinearSVC 
from sklearn.svm import SVC 
from sklearn import datasets, linear_model
from sklearn.model_selection import cross_val_score
import numpy as np

#for cross val
genre_list = train_genre.tolist()

#for submission
#genre_list = genres.tolist()

#linear
svclassifier2 = SVC(kernel='linear', C=0.8) 

#polynomial 
#svclassifier = SVC(kernel='poly', degree=8)

#gaussian
svclassifier = SVC(kernel='rbf', gamma=0.009, C=1.8)

#svclassifier = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=1e-4)

#sigmoid
#svclassifier = SVC(kernel='sigmoid')

#svm_scores = cross_val_score(svclassifier, csv_data[:,(3,4,5)], genre_list, cv=10, scoring='accuracy')
#print(svm_scores)

#for cross val
svclassifier.fit(train_array, genre_list) 
y_svm1 = svclassifier.predict(test_array) 

svclassifier2.fit(train_array, genre_list) 
y_svm2 = svclassifier2.predict(test_array) 

#for submission
#svclassifier.fit(csv_data[:,(3,4,5)], genre_list) 
#y_svm1 = svclassifier.predict(test_data_csv[:,(3,4,5)])

#svclassifier.fit(csv_data[:,(4,5)], genre_list) 
#y_svm2 = svclassifier.predict(test_data_csv[:,(4,5)])

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

genre_list =  train_genre.tolist()
#genre_list = genres.tolist()


#for cross val
neigh1 = KNeighborsClassifier(n_neighbors=5)
neigh1.fit(train_array_knn,genre_list)
neigh_predict1 = neigh1.predict(test_array_knn) 

neigh2 = KNeighborsClassifier(n_neighbors=23)
neigh2.fit(train_array_knn,genre_list)
neigh_predict2 = neigh2.predict(test_array_knn)

#for submission
#neigh1 = KNeighborsClassifier(n_neighbors=5)
#neigh1.fit(csv_data[:,(4,5)],genre_list)
#neigh_predict1 = neigh1.predict(test_data_csv[:,(4,5)]) 

#neigh2 = KNeighborsClassifier(n_neighbors=17)
#neigh2.fit(csv_data[:,(4,5)],genre_list)
#neigh_predict2 = neigh2.predict(test_data_csv[:,(4,5)]) 

# COMBINE CNN, KNN, and SVM
#one_hot1 = to_categorical(neigh_predict1)*0.68
#one_hot2 = to_categorical(y_svm1)*0.68
#one_hot3 = to_categorical(y_svm2)*0.68
#one_hot4 = to_categorical(neigh_predict2)*0.68

genre_pred1 = y_svm1.tolist()
genre_pred2 = y_svm2.tolist()
test_genre_list = test_genre.tolist()

acc1 = accuracy_score(test_genre_list, genre_pred1)
acc2 = accuracy_score(test_genre_list, genre_pred2)

if acc1 >= acc2:
  print("one_hot2")
  one_hot2 = to_categorical(y_svm1)*0.68
else:
  print("one_hot3")
  one_hot2 = to_categorical(y_svm2)*0.68

  
genre_pred3 = neigh_predict1.tolist()
genre_pred4 = neigh_predict2.tolist()

acc3 = accuracy_score(test_genre_list, genre_pred3)
acc4 = accuracy_score(test_genre_list, genre_pred4)

if acc3 >= acc4:
  print("one_hot1")
  one_hot1 = to_categorical(neigh_predict1)*0.68
else:
  print("one_hot4")
  one_hot1 = to_categorical(neigh_predict2)*0.68


k_predict = predict + one_hot1+ one_hot2

#Overall accuracy
from sklearn.metrics import accuracy_score

genre_pred = np.argmax(k_predict,axis=1)
#genre_pred = y_svm

genre_pred_list = genre_pred.tolist()
test_genre_list = test_genre.tolist()

accuracy_score(test_genre_list, genre_pred_list)

model.summary()
  
model.save("movie_classifier.h5py")

predict_final = model.predict(x_test, batch_size=32, verbose=0, steps=None)

#for submission
y_svm1_final = svclassifier.predict(test_data_csv[:,(3,4,5)])

y_svm2_final = svclassifier2.predict(test_data_csv[:,(3,4,5)])

neigh_predict1_final = neigh1.predict(test_data_csv[:,(4,5)]) 

neigh_predict2_final = neigh2.predict(test_data_csv[:,(4,5)]) 

# COMBINE CNN, KNN, and SVM
one_hot1_final = to_categorical(neigh_predict1_final)*0.68
one_hot2_final = to_categorical(y_svm1_final)*0.68
one_hot3_final = to_categorical(y_svm2_final)*0.68
one_hot4_final = to_categorical(neigh_predict2_final)*0.68

k_predict_final = one_hot2_final + one_hot4_final + predict_final
print(k_predict_final)
k_predict_final.shape

# write test predictions in csv file

from google.colab import files
import numpy as np
import csv
k_predict_class = np.argmax(k_predict_final,axis=1)
with open('naw.csv','w') as f:
    writer = csv.writer(f)
    for val in k_predict_class:
        writer.writerows(str(val))    
f.close()

files.download("naw.csv") # download csv file of test predictions

#Using cross validation to find the best k for KNN
from sklearn.neighbors import KNeighborsClassifier
from sklearn import datasets, linear_model
from sklearn.model_selection import cross_val_score
import numpy as np

genre_list = genres.tolist()
#genre_list = train_genre.tolist()


# creating odd list of K for KNN
klist = list(range(1,50))

# subsetting just the odd ones
neighbors = filter(lambda x: x % 2 != 0, klist)

# empty list that will hold cv scores
cv_scores = []

# perform 10-fold cross validation
for k in neighbors:
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn, csv_data[:,(4,5)], genre_list, cv=10, scoring='accuracy')
    cv_scores.append(scores.mean())

print("k best =",cv_scores.index(max(cv_scores)))
print("accuracy =",cv_scores[23])